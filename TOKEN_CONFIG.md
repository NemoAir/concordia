# Concordia Token é…ç½®ç»Ÿä¸€æ–‡æ¡£

**ç‰ˆæœ¬**: 1.0.0  
**æœ€åæ›´æ–°**: 2025-11-08 Session 1  
**ç»´æŠ¤çŠ¶æ€**: ğŸŸ¡ å®¡è®¡è¿›è¡Œä¸­

---

## ğŸ“– æ–‡æ¡£è¯´æ˜

æœ¬æ–‡æ¡£é›†ä¸­è®°å½• Concordia æ¡†æ¶ä¸­æ‰€æœ‰ä¸ token é™åˆ¶ç›¸å…³çš„é…ç½®å‚æ•°ã€‚

### ç›®çš„
1. **é›†ä¸­ç®¡ç†**ï¼šä¸€å¤„æŸ¥çœ‹æ‰€æœ‰ token é…ç½®
2. **é¿å…å†²çª**ï¼šè¯†åˆ«ä¸ä¸€è‡´çš„é…ç½®
3. **æ˜“äºè°ƒä¼˜**ï¼šå¿«é€Ÿå®šä½éœ€è¦è°ƒæ•´çš„å‚æ•°
4. **è·¨ Session è¿ç»­æ€§**ï¼šå®Œæ•´è®°å½•ä¾¿äºé•¿æœŸç»´æŠ¤

### ä½¿ç”¨åœºæ™¯
- ğŸ”§ **æ€§èƒ½è°ƒä¼˜**ï¼šé‡åˆ°æˆªæ–­é—®é¢˜æ—¶æŸ¥æ‰¾ç›¸å…³å‚æ•°
- ğŸ“Š **ç³»ç»Ÿåˆ†æ**ï¼šäº†è§£å„ç»„ä»¶çš„ token é¢„ç®—
- ğŸš€ **æ–°åŠŸèƒ½å¼€å‘**ï¼šæ·»åŠ æ–°ç»„ä»¶æ—¶å‚è€ƒç°æœ‰é…ç½®
- ğŸ› **é—®é¢˜æ’æŸ¥**ï¼šå®šä½ MAX_TOKENS é”™è¯¯æ¥æº

---

## ğŸ¯ é…ç½®å±‚çº§

Concordia çš„ token é…ç½®åˆ†ä¸º 4 ä¸ªå±‚çº§ï¼š

```
Level 1: å…¨å±€é»˜è®¤å€¼ (Global Defaults)
   â†“
Level 2: æ¨¡å—çº§é…ç½® (Module Configs)
   â†“
Level 3: ç»„ä»¶çº§é…ç½® (Component Configs)
   â†“
Level 4: å‡½æ•°è°ƒç”¨é…ç½® (Call-site Configs)
```

**ä¼˜å…ˆçº§**ï¼šLevel 4 > Level 3 > Level 2 > Level 1

---

## ğŸ“Š Level 1: å…¨å±€é»˜è®¤å€¼

è¿™äº›æ˜¯æ¡†æ¶æœ€åº•å±‚çš„é»˜è®¤é…ç½®ï¼Œå½±å“æ‰€æœ‰æœªæ˜¾å¼æŒ‡å®šçš„è°ƒç”¨ã€‚

### 1.1 Document å±‚é»˜è®¤å€¼

**æ–‡ä»¶**: `concordia/document/interactive_document.py`

```python
# Line 27-28
DEFAULT_MAX_CHARACTERS = 16384  
DEFAULT_MAX_TOKENS = 4096  # = DEFAULT_MAX_CHARACTERS // 4
```

| å‚æ•° | å€¼ | è¯´æ˜ | å½±å“èŒƒå›´ |
|------|-----|------|---------|
| `DEFAULT_MAX_CHARACTERS` | 16384 | æœ€å¤§å­—ç¬¦æ•° | æ‰€æœ‰ InteractiveDocument å®ä¾‹ |
| `DEFAULT_MAX_TOKENS` | 4096 | æœ€å¤§ token æ•° | æ‰€æœ‰ `open_question()` è°ƒç”¨ |

**ç”¨é€”**:
- `InteractiveDocument.open_question()` çš„é»˜è®¤ `max_tokens`
- æ‰€æœ‰åŸºäºæ–‡æ¡£çš„äº¤äº’å¼å¯¹è¯ç”Ÿæˆ

**ä¿®æ”¹å†å²**:
- åˆå§‹å€¼: `4000 chars / 1000 tokens`
- 2025-11-08: å¢åŠ åˆ° `16384 chars / 4096 tokens` (commit: 604a3fd)
- **åŸå› **: è§£å†³å¤šè¯­è¨€ï¼ˆä¸­æ–‡ï¼‰å†…å®¹æˆªæ–­é—®é¢˜

**å½±å“åˆ†æ**:
- âœ… å‡å°‘ MAX_TOKENS é”™è¯¯
- âœ… æ”¯æŒæ›´é•¿çš„æ¨ç†é“¾
- âš ï¸ å¢åŠ  API æˆæœ¬
- âš ï¸ å¢åŠ å“åº”å»¶è¿Ÿ

**å»ºè®®**:
- ä¿æŒå½“å‰å€¼ 4096 ç”¨äºä¸€èˆ¬åœºæ™¯
- ç‰¹æ®Šç»„ä»¶ï¼ˆå¦‚é•¿å¯¹è¯ï¼‰å¯ä»¥æ˜¾å¼æŒ‡å®šæ›´å¤§å€¼
- ç®€å•æŸ¥è¯¢å¯ä»¥æ˜¾å¼æŒ‡å®šæ›´å°å€¼ï¼ˆå¦‚ 500-1000ï¼‰

---

### 1.2 Language Model å±‚é»˜è®¤å€¼

**æ–‡ä»¶**: `concordia/language_model/language_model.py`

> **å¾…å®¡è®¡** - éœ€è¦å®Œæ•´é˜…è¯»æ­¤æ–‡ä»¶

**å·²çŸ¥çš„**:
```python
DEFAULT_TEMPERATURE = 1.0
DEFAULT_TOP_P = 1.0
DEFAULT_TOP_K = 40
# DEFAULT_MAX_TOKENS å€¼å¾…ç¡®è®¤
```

**éœ€è¦ç¡®è®¤**:
- [ ] æ˜¯å¦æœ‰æ¨¡å‹çº§åˆ«çš„ `DEFAULT_MAX_TOKENS`ï¼Ÿ
- [ ] ä¸åŒæ¨¡å‹ç±»å‹çš„é»˜è®¤å€¼å·®å¼‚ï¼Ÿ
- [ ] Safety settings å¯¹ token çš„å½±å“ï¼Ÿ

---

## ğŸ“Š Level 2: æ¨¡å—çº§é…ç½®

### 2.1 Thought Chains æ¨¡å—

**æ–‡ä»¶**: `concordia/thought_chains/thought_chains.py`

> **å¾…ç³»ç»Ÿå®¡è®¡** - ç›®å‰å·²çŸ¥çš„éƒ¨åˆ†é…ç½®

**å·²çŸ¥çš„ max_tokens é…ç½®**:

| å‡½æ•°/æ–¹æ³• | è¡Œå· | max_tokens | ç”¨é€” |
|-----------|------|-----------|------|
| (ç›´æ¥å¼•ç”¨) | 74 | 2500 | æå–è§’è‰²å¼•è¿° |
| `result_to_who_what_where` | 140 | 3000 | äº‹ä»¶å› æœåˆ†æ |
| `result_to_who_what_where` | 151 | 3000 | å› æœé™ˆè¿°é‡å†™ |
| `attempt_to_result` | 176 | 3000 | å°è¯•è¡ŒåŠ¨ç»“æœ |
| `result_to_who_what_where` | 200 | 3000 | ä½ç½®æŸ¥è¯¢ |
| `result_to_who_what_where` | 205 | 3000 | è¡ŒåŠ¨æ„å›¾æŸ¥è¯¢ |
| `result_to_who_what_where` | 214 | 3000 | ç»“æœæè¿° |
| `result_to_who_what_where` | 219 | 3000 | æœ€å¯èƒ½ç»“æœ |
| `result_to_who_what_where` | 249 | 3000 | äº‹ä»¶é‡å†™ |
| (å…¶ä»–) | 282, 316, 356, 436, 510, 633, 678, 692, 716, 767 | 2200-3500 | å„ç§æ¨ç†ä»»åŠ¡ |

**è§‚å¯Ÿ**:
- å¤§éƒ¨åˆ†ä½¿ç”¨ 3000 tokens
- æœ‰ä¸€ä¸ª 2200ï¼Œä¸€ä¸ª 2500ï¼Œä¸€ä¸ª 3500
- **ä¸ä¸€è‡´æ€§**: éœ€è¦è¯„ä¼°æ˜¯å¦åº”è¯¥ç»Ÿä¸€

**å¾…å®¡è®¡**:
- [ ] å®Œæ•´é˜…è¯»æ–‡ä»¶ï¼Œç¡®è®¤æ‰€æœ‰ token é…ç½®
- [ ] åˆ†ææ¯ä¸ªå€¼çš„åˆç†æ€§
- [ ] å»ºè®®ç»Ÿä¸€æˆ–å·®å¼‚åŒ–é…ç½®

---

## ğŸ“Š Level 3: ç»„ä»¶çº§é…ç½®

### 3.1 Agent ç»„ä»¶

#### 3.1.1 QuestionOfRecentMemories

**æ–‡ä»¶**: `concordia/components/agent/question_of_recent_memories.py`

```python
# Line ~390 (å…·ä½“è¡Œå·å¾…ç¡®è®¤)
max_tokens=4096  # åŸå€¼: 1000
```

**ç”¨é€”**: Agent æŸ¥è¯¢æœ€è¿‘è®°å¿†æ—¶çš„ token é™åˆ¶

**ä¿®æ”¹å†å²**:
- åˆå§‹å€¼: 1000
- 2025-11-08: å¢åŠ åˆ° 4096 (commit: d055504)

**ä¾èµ–**:
- ä¾èµ– `InteractiveDocument.open_question()`
- é—´æ¥å— `DEFAULT_MAX_TOKENS` å½±å“

---

#### 3.1.2 ConcatActComponent

**æ–‡ä»¶**: `concordia/components/agent/concat_act_component.py`

```python
# Line ~170 (å…·ä½“è¡Œå·å¾…ç¡®è®¤)
max_tokens=4096  # åŸå€¼: 2200
```

**ç”¨é€”**: Agent æ‹¼æ¥å¤šä¸ªè¡ŒåŠ¨ç»„ä»¶è¾“å‡º

**ä¿®æ”¹å†å²**:
- åˆå§‹å€¼: 2200
- 2025-11-08: å¢åŠ åˆ° 4096 (commit: d055504)

---

### 3.2 Game Master ç»„ä»¶

#### 3.2.1 SwitchAct

**æ–‡ä»¶**: `concordia/components/game_master/switch_act.py`

```python
# Line ~340 (å…·ä½“è¡Œå·å¾…ç¡®è®¤)
max_tokens=4096  # åŸå€¼: 1000
```

**ç”¨é€”**: GM å†³å®šæ˜¯å¦åˆ‡æ¢å½“å‰è¡ŒåŠ¨è€…

**ä¿®æ”¹å†å²**:
- åˆå§‹å€¼: 1000
- 2025-11-08: å¢åŠ åˆ° 4096 (commit: d055504)

---

#### 3.2.2 NextActing

**æ–‡ä»¶**: `concordia/components/game_master/next_acting.py`

```python
# Line ~650 (å…·ä½“è¡Œå·å¾…ç¡®è®¤)
max_tokens=4096  # åŸå€¼: 1024
```

**ç”¨é€”**: GM é€‰æ‹©ä¸‹ä¸€ä¸ªè¡ŒåŠ¨çš„è§’è‰²

**ä¿®æ”¹å†å²**:
- åˆå§‹å€¼: 1024
- 2025-11-08: å¢åŠ åˆ° 4096 (commit: d055504)

---

#### 3.2.3 MakeObservation

**æ–‡ä»¶**: `concordia/components/game_master/make_observation.py`

```python
# Line 173
max_tokens=3000
```

**ç”¨é€”**: ç”Ÿæˆè§’è‰²è§‚å¯Ÿæè¿°

**çŠ¶æ€**: æœªä¿®æ”¹ï¼ˆä½¿ç”¨æ˜¾å¼ 3000ï¼‰

**å¾…è¯„ä¼°**: æ˜¯å¦éœ€è¦å¢åŠ ï¼Ÿ

---

#### 3.2.4 FormativeMemoriesInitializer

**æ–‡ä»¶**: `concordia/components/game_master/formative_memories_initializer.py`

> **å¾…ç³»ç»Ÿå®¡è®¡** - æ­¤æ–‡ä»¶åŒ…å«å¤šä¸ª token é…ç½®

**å·²çŸ¥é…ç½®**:
- è¯­è¨€æ£€æµ‹å…ƒæç¤º: `max_tokens=500`
- å…¶ä»–ç”Ÿæˆä»»åŠ¡: å¾…ç¡®è®¤

**ç‰¹æ®Šæ€§**: æ­¤ç»„ä»¶å®ç°äº†è¯­è¨€è‡ªé€‚åº”æ¶æ„

---

## ğŸ“Š Level 4: å‡½æ•°è°ƒç”¨é…ç½®

è¿™ä¸€å±‚çº§æ˜¯ä»£ç ä¸­ç›´æ¥è°ƒç”¨æ—¶ä¼ é€’çš„ `max_tokens` å‚æ•°ã€‚

> **å¤§é‡å¾…å®¡è®¡** - éœ€è¦ç³»ç»Ÿæ€§åœ°è¯»å–æ‰€æœ‰æ–‡ä»¶

**ç¤ºä¾‹** (examples/tutorial_chinese.ipynb):
```python
# Cell 7: æµ‹è¯•è¯­è¨€æ¨¡å‹
response = model.sample_text(
    prompt="...",
    max_tokens=500,  # æ˜¾å¼æŒ‡å®š
    terminators=('\n',)
)
```

---

## ğŸ” å¾…å®¡è®¡çš„å…³é”®æ–‡ä»¶

### ä¼˜å…ˆçº§ 1 (æ ¸å¿ƒæ¨¡å—)

- [ ] `concordia/language_model/language_model.py`
- [ ] `concordia/language_model/google_aistudio_model.py`
- [ ] `concordia/language_model/cloud_vertex_model.py`
- [ ] `concordia/language_model/utils.py`
- [ ] `concordia/document/interactive_document.py` âœ…
- [ ] `concordia/thought_chains/thought_chains.py` (éƒ¨åˆ†å·²çŸ¥)

### ä¼˜å…ˆçº§ 2 (ç»„ä»¶)

**Agent ç»„ä»¶** (~20 ä¸ªæ–‡ä»¶):
- [ ] `concordia/components/agent/question_of_recent_memories.py` âœ…
- [ ] `concordia/components/agent/concat_act_component.py` âœ…
- [ ] `concordia/components/agent/*.py` (å…¶ä»–)

**Game Master ç»„ä»¶** (~30 ä¸ªæ–‡ä»¶):
- [ ] `concordia/components/game_master/formative_memories_initializer.py` (éƒ¨åˆ†å·²çŸ¥)
- [ ] `concordia/components/game_master/make_observation.py` (éƒ¨åˆ†å·²çŸ¥)
- [ ] `concordia/components/game_master/switch_act.py` âœ…
- [ ] `concordia/components/game_master/next_acting.py` âœ…
- [ ] `concordia/components/game_master/*.py` (å…¶ä»–)

### ä¼˜å…ˆçº§ 3 (å…¶ä»–æ¨¡å—)

- [ ] `concordia/agents/*.py`
- [ ] `concordia/environment/*.py`
- [ ] `concordia/associative_memory/*.py`
- [ ] `concordia/prefabs/*.py`

---

## ğŸ“ˆ ç»Ÿè®¡åˆ†æ

### å½“å‰çŠ¶æ€ (Session 1)

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| å·²å®¡è®¡æ–‡ä»¶ | 6 | éƒ¨åˆ†å®Œæˆï¼Œéç³»ç»Ÿå®¡è®¡ |
| å‘ç°å‚æ•° | ~25 | ä¼°è®¡å€¼ |
| å·²ç»Ÿä¸€é…ç½® | 0 | å°šæœªå¼€å§‹é‡æ„ |
| å¾…å®¡è®¡æ–‡ä»¶ | ~100+ | å®Œæ•´å®¡è®¡å¾…å¼€å§‹ |

### Token å€¼åˆ†å¸ƒ (å·²çŸ¥)

```
500   â–ˆ (1ä¸ª)  è¯­è¨€æ£€æµ‹
1000  â–ˆâ–ˆâ–ˆ (3ä¸ª) æ—§é»˜è®¤å€¼
2200  â–ˆ (1ä¸ª)  å¯¹è¯ç”Ÿæˆ
2500  â–ˆ (1ä¸ª)  å¼•è¿°æå–
3000  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (10+ä¸ª) æ¨ç†é“¾æ ‡å‡†å€¼
3500  â–ˆ (1ä¸ª)  å¤æ‚æ¨ç†
4096  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (6ä¸ª) æ–°å¢é«˜é™åˆ¶
```

**è§‚å¯Ÿ**:
- å¤§éƒ¨åˆ†ä½¿ç”¨ 3000 æˆ– 4096
- å­˜åœ¨ä¸€äº›å¼‚å¸¸å€¼ï¼ˆ500, 2200, 2500, 3500ï¼‰
- éœ€è¦è¯„ä¼°æ˜¯å¦åº”è¯¥æ ‡å‡†åŒ–

---

## ğŸ¯ é‡æ„å»ºè®®

### é˜¶æ®µ 1: åˆ›å»ºé…ç½®ç±»

```python
# concordia/config/token_config.py (å»ºè®®)

class TokenLimits:
    """ç»Ÿä¸€çš„ Token é™åˆ¶é…ç½®"""
    
    # å…¨å±€é»˜è®¤å€¼
    DEFAULT = 4096
    
    # è¯­ä¹‰å±‚çº§
    SHORT_RESPONSE = 500      # ç®€çŸ­å›ç­”ï¼ˆå¦‚åå­—ã€æ—¥æœŸï¼‰
    MEDIUM_RESPONSE = 1000    # ä¸­ç­‰å›ç­”ï¼ˆå¦‚ç®€çŸ­æè¿°ï¼‰
    LONG_RESPONSE = 2000      # é•¿å›ç­”ï¼ˆå¦‚å®Œæ•´äº‹ä»¶ï¼‰
    VERY_LONG_RESPONSE = 4096 # è¶…é•¿å›ç­”ï¼ˆå¦‚å¤æ‚æ¨ç†ï¼‰
    
    # åŠŸèƒ½åˆ†ç±»
    LANGUAGE_DETECTION = 500
    SIMPLE_QUERY = 1000
    MEMORY_QUERY = 2000
    EVENT_RESOLUTION = 3000
    COMPLEX_REASONING = 4096
    BACKSTORY_GENERATION = 4096
```

### é˜¶æ®µ 2: é€æ­¥æ›¿æ¢

1. æ›¿æ¢æ‰€æœ‰ç¡¬ç¼–ç å€¼ä¸ºé…ç½®ç±»å¼•ç”¨
2. ä¿æŒå‘åå…¼å®¹
3. æ·»åŠ å¼ƒç”¨è­¦å‘Š

### é˜¶æ®µ 3: æ–‡æ¡£å’Œæµ‹è¯•

1. æ›´æ–°æ‰€æœ‰æ–‡æ¡£
2. æ·»åŠ é…ç½®æµ‹è¯•
3. æä¾›è¿ç§»æŒ‡å—

---

## ğŸš¨ æ³¨æ„äº‹é¡¹

### ä¿®æ”¹é£é™©

1. **API æˆæœ¬**: å¢åŠ  max_tokens ä¼šå¢åŠ  API è°ƒç”¨æˆæœ¬
2. **å»¶è¿Ÿ**: æ›´å¤§çš„ token é™åˆ¶å¯èƒ½å¢åŠ å“åº”æ—¶é—´
3. **å…¼å®¹æ€§**: æŸäº›æ¨¡å‹å¯èƒ½æœ‰æ›´ä½çš„é™åˆ¶
4. **è´¨é‡**: å¹¶éæ‰€æœ‰åœºæ™¯éƒ½éœ€è¦é•¿å›ç­”

### æœ€ä½³å®è·µ

1. **æœ€å°å¿…è¦åŸåˆ™**: ä½¿ç”¨æ»¡è¶³éœ€æ±‚çš„æœ€å°å€¼
2. **æ˜¾å¼ä¼˜äºéšå¼**: é‡è¦åœºæ™¯æ˜¾å¼æŒ‡å®š max_tokens
3. **åˆ†å±‚é…ç½®**: å…¨å±€é»˜è®¤ + ç»„ä»¶è¦†ç›– + è°ƒç”¨è¦†ç›–
4. **å……åˆ†æµ‹è¯•**: ä¿®æ”¹åæµ‹è¯•å„ç§åœºæ™¯

---

## ğŸ“ å®¡è®¡æ—¥å¿—

| æ—¥æœŸ | Session | å®¡è®¡å†…å®¹ | å‘ç°æ•° | æäº¤ |
|------|---------|---------|--------|------|
| 2025-11-08 | 1 | åˆ›å»ºè¿½è¸ªç³»ç»Ÿ | 6 | - |
| - | - | å¾…ç»§ç»­... | - | - |

---

## ğŸ”„ ä¸‹ä¸€æ­¥

1. âœ… åˆ›å»ºæœ¬æ–‡æ¡£
2. â³ ç”Ÿæˆå®Œæ•´æ–‡ä»¶æ¸…å•
3. â³ å¼€å§‹ç³»ç»Ÿå®¡è®¡ `language_model/`
4. â³ å®Œæˆæ‰€æœ‰æ ¸å¿ƒæ¨¡å—å®¡è®¡
5. â³ è®¾è®¡é…ç½®ç±»
6. â³ å®æ–½é‡æ„

---

*æœ¬æ–‡æ¡£å°†éšå®¡è®¡è¿›åº¦æŒç»­æ›´æ–°*
*æ¯å‘ç°æ–°å‚æ•°ç«‹å³æ·»åŠ åˆ°å¯¹åº”ç« èŠ‚*


---

## ğŸ” Phase 1 å®¡è®¡ç»“æœ

### Phase 1, Stage 1.1: Language Model æ ¸å¿ƒ âœ…

**å®¡è®¡æ—¶é—´**: 2025-11-08 Session 1
**æ–‡ä»¶æ•°é‡**: 19 ä¸ªæ–‡ä»¶
**å‘ç°å‚æ•°**: 20+

#### å…³é”®å‘ç°æ€»ç»“

1. **å…¨å±€é»˜è®¤å€¼** (`language_model.py` Line 27)
   ```python
   DEFAULT_MAX_TOKENS = 5000
   ```
   - è¿™æ˜¯æ‰€æœ‰è¯­è¨€æ¨¡å‹çš„åŸºç¡€é»˜è®¤å€¼
   - ä¼˜å…ˆçº§ï¼šè¯­è¨€æ¨¡å‹å±‚ > æ–‡æ¡£å±‚ (4096)

2. **æ¨¡å‹ç‰¹å®šçš„ç¡¬ç¼–ç å€¼**

   | æ¨¡å‹ | åœºæ™¯ | max_tokens | æ–‡ä»¶ | è¡Œå· |
   |------|------|-----------|------|------|
   | Google AI Studio | sample_choice | 8192 | `google_aistudio_model.py` | 303 |
   | Cloud Vertex | sample_choice | 2048 | `cloud_vertex_model.py` | 172 |
   | Mistral (completion) | sample_choice | 256 | `mistral_model.py` | 263 |
   | Mistral (chat) | sample_choice | 3 | `mistral_model.py` | 271 |
   | VLLM | logprobs only | 1 | `vllm_model.py` | 211 |
   | Together AI | sample_choice | 1 | `together_ai.py` | 294 |

3. **æ¨¡å‹ç‰¹å®šçš„é™åˆ¶å¸¸é‡**

   ```python
   # together_ai.py Line 53
   _DEFAULT_NUM_RESPONSE_TOKENS = 5000
   # ç”¨äºcap max_tokens: min(max_tokens, 5000)
   
   # google_cloud_custom_model.py Line 33
   _DEFAULT_MAX_TOKENS = 5000
   # ç”¨äºcap max_tokens: min(max_tokens, 5000)
   
   # amazon_bedrock_model.py Line 28-32
   MODEL_MAX_OUTPUT_TOKENS_LIMITS = {
       'ai21.jamba-instruct-v1:0': 4096,
       'ai21.jamba-1.5-mini-v1:0': 4096,
       'ai21.jamba-1.5-large-v1:0': 4096,
       'meta.llama3-1-405b-instruct-v1:0': 4096,
       'us.meta.llama3-2-90b-instruct-v1:0': 4096,
   }
   # ä¸åŒæ¨¡å‹æœ‰ä¸åŒçš„ç¡¬é™åˆ¶
   ```

#### âš ï¸ å‘ç°çš„ä¸ä¸€è‡´æ€§

1. **sample_choice çš„ token é™åˆ¶æä¸ä¸€è‡´**
   - Google AI Studio: 8192
   - Cloud Vertex: 2048
   - Mistral completion: 256
   - Mistral chat: 3
   - Together AI: 1
   - VLLM: 1
   
   **åŸå› **: ä¸åŒçš„å®ç°ç­–ç•¥
   - æœ‰çš„ç”Ÿæˆå®Œæ•´å›ç­”å†æå–
   - æœ‰çš„åªç”Ÿæˆé€‰é¡¹å­—æ¯
   - æœ‰çš„ä½¿ç”¨ logprobs ä¸ç”Ÿæˆæ–‡æœ¬

2. **è¯­è¨€æ¨¡å‹å±‚ vs æ–‡æ¡£å±‚çš„é»˜è®¤å€¼**
   - `language_model.DEFAULT_MAX_TOKENS` = **5000**
   - `interactive_document.DEFAULT_MAX_TOKENS` = **4096** (åˆšä¿®æ”¹)
   
   **å½±å“**: 
   - ç›´æ¥è°ƒç”¨ `model.sample_text()` é»˜è®¤ 5000
   - é€šè¿‡ `InteractiveDocument.open_question()` é»˜è®¤ 4096
   - å¯èƒ½å¯¼è‡´æ··æ·†

#### ğŸ“Š å®Œæ•´æ–‡ä»¶åˆ—è¡¨

| æ–‡ä»¶ | Token é…ç½® | è¯´æ˜ |
|------|-----------|------|
| `__init__.py` | æ—  | ç©ºæ–‡ä»¶ |
| `language_model.py` | DEFAULT_MAX_TOKENS = 5000 | â­ åŸºç¡€æ¥å£ |
| `google_aistudio_model.py` | 5000 (é»˜è®¤), 8192 (choice) | â­ Gemini API |
| `cloud_vertex_model.py` | 5000 (é»˜è®¤), 2048 (choice) | Google Cloud |
| `mistral_model.py` | 5000 (é»˜è®¤), 256/3 (choice) | Mistral API |
| `together_ai.py` | 5000 (é»˜è®¤, capped) | Together AI |
| `amazon_bedrock_model.py` | 5000 (é»˜è®¤), æ¨¡å‹ç‰¹å®šä¸Šé™ | AWS Bedrock |
| `google_cloud_custom_model.py` | 5000 (capped) | Custom model |
| `vllm_model.py` | 5000 (é»˜è®¤), 1 (logprobs) | vLLM æœ¬åœ° |
| `ollama_model.py` | 5000 (é»˜è®¤) | Ollama æœ¬åœ° |
| `langchain_ollama_model.py` | 5000 (é»˜è®¤) | LangChain + Ollama |
| `pytorch_gemma_model.py` | 5000 (é»˜è®¤) | PyTorch Gemma |
| `base_gpt_model.py` | 5000 (é»˜è®¤) | GPT åŸºç±» |
| `gpt_model.py` | 5000 (é»˜è®¤) | OpenAI GPT |
| `azure_gpt_model.py` | 5000 (é»˜è®¤) | Azure GPT |
| `no_language_model.py` | 5000 (é»˜è®¤) | å ä½ç¬¦æ¨¡å‹ |
| `retry_wrapper.py` | é€ä¼  | é‡è¯•åŒ…è£…å™¨ |
| `call_limit_wrapper.py` | é€ä¼  | é™æµåŒ…è£…å™¨ |
| `utils.py` | æ— é…ç½® | å·¥å…·å‡½æ•° |

#### ğŸ¯ å»ºè®®

1. **æ ‡å‡†åŒ– sample_choice çš„è¡Œä¸º**
   - æ–‡æ¡£åŒ–ä¸åŒå®ç°çš„å·®å¼‚
   - æˆ–ç»Ÿä¸€åˆ°ä¸€ä¸ªåˆç†çš„å€¼ï¼ˆå¦‚ 1000-2000ï¼‰

2. **ç»Ÿä¸€å±‚çº§é»˜è®¤å€¼**
   - è€ƒè™‘å°† `language_model.DEFAULT_MAX_TOKENS` ä¹Ÿæ”¹ä¸º 4096
   - æˆ–åœ¨æ–‡æ¡£å±‚æ˜¾å¼å¼•ç”¨è¯­è¨€æ¨¡å‹å±‚çš„é»˜è®¤å€¼

3. **æ·»åŠ é…ç½®ç±»**
   - åˆ›å»º `TokenLimits` ç±»ç»Ÿä¸€ç®¡ç†
   - åŒºåˆ†ä¸åŒåœºæ™¯çš„æ¨èå€¼

---

