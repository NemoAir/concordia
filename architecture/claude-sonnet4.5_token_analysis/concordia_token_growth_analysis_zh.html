<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Concordia Token 动态增长与累积分析</title>
    <style>
        body {
            font-family: 'Segoe UI', Arial, sans-serif;
            line-height: 1.8;
            max-width: 1400px;
            margin: 0 auto;
            padding: 30px;
            background-color: #f5f5f5;
        }
        h1 {
            color: #2c3e50;
            border-bottom: 4px solid #e74c3c;
            padding-bottom: 15px;
            margin-bottom: 30px;
        }
        h2 {
            color: #34495e;
            border-left: 5px solid #e74c3c;
            padding-left: 15px;
            margin-top: 40px;
            background-color: #ecf0f1;
            padding: 10px 10px 10px 15px;
        }
        h3 {
            color: #555;
            margin-top: 25px;
            border-bottom: 2px solid #95a5a6;
            padding-bottom: 8px;
        }
        .section {
            background-color: white;
            padding: 25px;
            margin: 20px 0;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        .growth-chart {
            background-color: #f8f9fa;
            border: 2px solid #dee2e6;
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
            font-family: monospace;
            white-space: pre;
            overflow-x: auto;
        }
        .data-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background-color: white;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .data-table th {
            background-color: #e74c3c;
            color: white;
            padding: 12px;
            text-align: left;
            font-weight: 600;
        }
        .data-table td {
            padding: 10px 12px;
            border-bottom: 1px solid #ddd;
        }
        .data-table tr:hover {
            background-color: #f8f9fa;
        }
        .warning-box {
            background-color: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            margin: 20px 0;
        }
        .danger-box {
            background-color: #f8d7da;
            border-left: 4px solid #dc3545;
            padding: 15px;
            margin: 20px 0;
        }
        .info-box {
            background-color: #d1ecf1;
            border-left: 4px solid #17a2b8;
            padding: 15px;
            margin: 20px 0;
        }
        .code-ref {
            font-family: 'Courier New', monospace;
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-size: 0.9em;
            color: #e74c3c;
        }
        .number-large {
            font-size: 1.3em;
            font-weight: bold;
            color: #e74c3c;
        }
        .formula {
            background-color: #e9ecef;
            padding: 10px;
            border-radius: 5px;
            margin: 10px 0;
            font-family: 'Courier New', monospace;
        }
        .highlight {
            background-color: #ffeb3b;
            padding: 2px 4px;
        }
    </style>
</head>
<body>
    <h1>📈 Concordia Token 动态增长与累积分析</h1>

    <div class="warning-box">
        <h3>🎯 本文档重点</h3>
        <p>本文档是 <strong>concordia_token_analysis_zh.html</strong> 的补充，专注于：</p>
        <ul>
            <li><strong>Token在游戏进程中的累积增长模式</strong></li>
            <li><strong>Memory Bank膨胀对Token的长期影响</strong></li>
            <li><strong>不同游戏阶段的Token消耗变化</strong></li>
            <li><strong>Token峰值预警和瓶颈识别</strong></li>
            <li><strong>实际运行场景的Token轨迹模拟</strong></li>
        </ul>
    </div>

    <div class="section">
        <h2>1. Memory Bank的动态增长模型</h2>

        <h3>1.1 Memory增长速率分析</h3>

        <p>Concordia的Memory Bank是一个<strong>只增不减</strong>的数据结构，每次add()操作都会永久存储记忆。</p>

        <div class="formula">
<strong>Memory增长公式：</strong>

M(t) = M₀ + R_obs × t_steps + R_reflect × t_steps + R_action × t_steps

其中：
├─ M(t): t步后的总Memory数量
├─ M₀: 初始Memory数量（通常为agent背景故事）
├─ R_obs: 每步观察产生的Memory数（通常=1，来自ObservationToMemory）
├─ R_reflect: 每步reflection产生的Memory数（取决于add_to_memory配置）
├─ R_action: 每步动作产生的Memory数（通常=0，action不直接存储）
└─ t_steps: 游戏步数

<strong>典型配置（R_obs=1, R_reflect=0）：</strong>
M(t) = M₀ + 1 × t_steps

<strong>示例：</strong>
├─ 初始背景故事: 10条
├─ 游戏100步后: M(100) = 10 + 100 = 110条
├─ 游戏500步后: M(500) = 10 + 500 = 510条
└─ 游戏1000步后: M(1000) = 10 + 1000 = 1010条
        </div>

        <h3>1.2 Memory Bank对Token消耗的影响</h3>

        <table class="data-table">
            <thead>
                <tr>
                    <th>游戏步数</th>
                    <th>Memory总量</th>
                    <th>retrieve_recent(25)返回Token</th>
                    <th>retrieve_recent(100)返回Token</th>
                    <th>LastNObservations(100)Token</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>0 (初始)</td>
                    <td>10</td>
                    <td>~1,000 (只有10条)</td>
                    <td>~1,000 (只有10条)</td>
                    <td>~500</td>
                </tr>
                <tr>
                    <td>10</td>
                    <td>20</td>
                    <td>~2,000</td>
                    <td>~2,000 (只有20条)</td>
                    <td>~1,000</td>
                </tr>
                <tr>
                    <td>50</td>
                    <td>60</td>
                    <td>~2,500</td>
                    <td>~6,000</td>
                    <td>~5,000</td>
                </tr>
                <tr>
                    <td>100</td>
                    <td>110</td>
                    <td>~2,500</td>
                    <td>~10,000</td>
                    <td>~5,000</td>
                </tr>
                <tr>
                    <td>200</td>
                    <td>210</td>
                    <td>~2,500</td>
                    <td>~10,000</td>
                    <td>~5,000</td>
                </tr>
                <tr>
                    <td>500</td>
                    <td>510</td>
                    <td>~2,500</td>
                    <td>~10,000</td>
                    <td>~5,000</td>
                </tr>
                <tr>
                    <td>1000</td>
                    <td>1010</td>
                    <td>~2,500</td>
                    <td>~10,000</td>
                    <td>~5,000</td>
                </tr>
            </tbody>
        </table>

        <div class="info-box">
            <h4>📊 关键观察</h4>
            <ul>
                <li><strong>retrieve_recent(k)有上限效应：</strong>当Memory总量超过k后，检索Token数稳定在k × 100</li>
                <li><strong>LastNObservations同样有上限：</strong>history_length限制了最大Token数</li>
                <li><strong>初期增长快，后期平稳：</strong>Token消耗在前50-100步增长明显，之后趋于平稳</li>
                <li><strong>Memory Bank大小不直接影响Token：</strong>只要检索量固定，即使有10000条Memory，检索Token也不变</li>
            </ul>
        </div>

        <h3>1.3 Memory Bank大小对性能的间接影响</h3>

        <div class="warning-box">
            <h4>⚠️ 虽然检索Token数固定，但Memory Bank增长仍有影响：</h4>
            <ol>
                <li><strong>Embedding计算成本：</strong>retrieve_associative需要计算query与所有Memory的余弦相似度，O(N)复杂度</li>
                <li><strong>检索质量下降：</strong>过多Memory可能导致相关性分散，检索精度降低</li>
                <li><strong>存储开销：</strong>Memory Bank存储在内存中的DataFrame，大量Memory消耗RAM</li>
                <li><strong>序列化成本：</strong>save/load Memory Bank的IO开销随大小线性增长</li>
            </ol>
            <p><strong>建议：</strong>对于长时间运行的游戏（1000+步），考虑实现Memory遗忘机制或重要性衰减。</p>
        </div>
    </div>

    <div class="section">
        <h2>2. 游戏进程中的Token累积轨迹</h2>

        <h3>2.1 单Agent游戏Token增长曲线（100步模拟）</h3>

        <div class="growth-chart">
Token消耗增长曲线（4玩家，Sequential Engine）

   Token (K)
   200 ┤                                                              ●
       │                                                          ●
   180 ┤                                                      ●
       │                                                  ●
   160 ┤                                              ●
       │                                          ●
   140 ┤                                      ●
       │                                  ●
   120 ┤                              ●●●●●●●●●●●●●●●●●●●●●●●●●●●● ← 平稳期
       │                          ●●●●
   100 ┤                      ●●●●
       │                  ●●●●
    80 ┤              ●●●●
       │          ●●●●
    60 ┤      ●●●●  ← 快速增长期
       │  ●●●●
    40 ┤●●●
       └┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬──→ Steps
        0    10    20    30    40    50    60    70    80    90   100

<strong>阶段划分：</strong>

<span class="highlight">第1-30步（启动期）：</span>
├─ Token快速增长（40K → 80K）
├─ Memory Bank从初始10条增长到40条
├─ LastNObservations从空增长到30条
└─ 每步增长约~1,300 tokens

<span class="highlight">第31-60步（加速期）：</span>
├─ Token继续增长（80K → 110K）
├─ Memory Bank从40条增长到70条
├─ LastNObservations从30条增长到60条
└─ 每步增长约~1,000 tokens

<span class="highlight">第61-100步（平稳期）：</span>
├─ Token增长趋缓（110K → 120K）
├─ Memory检索命中上限（retrieve_recent(25)稳定）
├─ LastNObservations命中上限（history_length=100）
└─ 每步增长约~250 tokens（仅来自新观察的描述变长）
        </div>

        <h3>2.2 逐步Token累积详细数据</h3>

        <table class="data-table">
            <thead>
                <tr>
                    <th>步数</th>
                    <th>单步Token</th>
                    <th>累积Token</th>
                    <th>Memory数量</th>
                    <th>主要Token来源</th>
                    <th>增长率</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>1</td>
                    <td>65,000</td>
                    <td>65,000</td>
                    <td>11 (10+1)</td>
                    <td>初始上下文较短</td>
                    <td>-</td>
                </tr>
                <tr>
                    <td>5</td>
                    <td>75,000</td>
                    <td>355,000</td>
                    <td>15</td>
                    <td>观察历史增长</td>
                    <td>+15%</td>
                </tr>
                <tr>
                    <td>10</td>
                    <td>85,000</td>
                    <td>750,000</td>
                    <td>20</td>
                    <td>Memory检索增加</td>
                    <td>+13%</td>
                </tr>
                <tr>
                    <td>20</td>
                    <td>98,000</td>
                    <td>1,850,000</td>
                    <td>30</td>
                    <td>接近检索上限</td>
                    <td>+15%</td>
                </tr>
                <tr>
                    <td>30</td>
                    <td>107,000</td>
                    <td>3,050,000</td>
                    <td>40</td>
                    <td>达到retrieve(25)上限</td>
                    <td>+9%</td>
                </tr>
                <tr>
                    <td>50</td>
                    <td>115,000</td>
                    <td>5,650,000</td>
                    <td>60</td>
                    <td>LastN达到上限</td>
                    <td>+7%</td>
                </tr>
                <tr>
                    <td>100</td>
                    <td>120,000</td>
                    <td>11,850,000</td>
                    <td>110</td>
                    <td>完全平稳</td>
                    <td>+4%</td>
                </tr>
                <tr>
                    <td>200</td>
                    <td>121,500</td>
                    <td>24,150,000</td>
                    <td>210</td>
                    <td>仅观察描述变化</td>
                    <td>+1.2%</td>
                </tr>
                <tr>
                    <td>500</td>
                    <td>123,000</td>
                    <td>61,250,000</td>
                    <td>510</td>
                    <td>几乎不增长</td>
                    <td>+1.2%</td>
                </tr>
            </tbody>
        </table>

        <div class="danger-box">
            <h4>🚨 累积Token警告</h4>
            <p><strong>100步游戏消耗约 11.85M tokens（约1185万）</strong></p>
            <p><strong>500步游戏消耗约 61.25M tokens（约6125万）</strong></p>
            <p>这是一个巨大的Token消耗，需要特别注意：</p>
            <ul>
                <li>按GPT-4定价（$10/1M input tokens），100步游戏约需 <strong>$118.5</strong></li>
                <li>按GPT-4定价，500步游戏约需 <strong>$612.5</strong></li>
                <li>实际成本可能更高（output tokens、多次重试等）</li>
                <li>这还只是<strong>4玩家</strong>的场景，玩家数增加会线性增长</li>
            </ul>
        </div>
    </div>

    <div class="section">
        <h2>3. 不同配置下的Token增长对比</h2>

        <h3>3.1 玩家数量对Token累积的影响</h3>

        <table class="data-table">
            <thead>
                <tr>
                    <th>步数</th>
                    <th>2玩家</th>
                    <th>4玩家</th>
                    <th>6玩家</th>
                    <th>8玩家</th>
                    <th>10玩家</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>10步累积</td>
                    <td>650K</td>
                    <td>750K</td>
                    <td>900K</td>
                    <td>1,050K</td>
                    <td>1,200K</td>
                </tr>
                <tr>
                    <td>50步累积</td>
                    <td>4.5M</td>
                    <td>5.65M</td>
                    <td>6.8M</td>
                    <td>7.95M</td>
                    <td>9.1M</td>
                </tr>
                <tr>
                    <td>100步累积</td>
                    <td>9.2M</td>
                    <td>11.85M</td>
                    <td>14.5M</td>
                    <td>17.15M</td>
                    <td>19.8M</td>
                </tr>
                <tr>
                    <td>200步累积</td>
                    <td>18.6M</td>
                    <td>24.15M</td>
                    <td>29.7M</td>
                    <td>35.25M</td>
                    <td>40.8M</td>
                </tr>
                <tr>
                    <td>500步累积</td>
                    <td>47M</td>
                    <td>61.25M</td>
                    <td>75.5M</td>
                    <td>89.75M</td>
                    <td>104M</td>
                </tr>
            </tbody>
        </table>

        <div class="growth-chart">
玩家数对累积Token的影响（100步）

   累积Token (M)
    20 ┤                                                            ●
       │                                                        ●
    18 ┤                                                    ●
       │                                                ●
    16 ┤                                            ●
       │                                        ●
    14 ┤                                    ●
       │                                ●
    12 ┤                            ●●●●
       │                        ●●●●
    10 ┤                    ●●●●
       │                ●●●●
     8 ┤            ●●●●
       │        ●●●●
     6 ┤    ●●●●
       │●●●●
     4 ┤
       └┬────┬────┬────┬────┬────┬────┬────┬────┬────┬────→ 玩家数
        2    3    4    5    6    7    8    9   10   11   12

<strong>线性关系：</strong>
累积Token(100步) ≈ 5.5M + 玩家数 × 1.32M

示例：
├─ 5玩家: 5.5M + 5 × 1.32M = 12.1M
├─ 7玩家: 5.5M + 7 × 1.32M = 14.74M
└─ 12玩家: 5.5M + 12 × 1.32M = 21.34M
        </div>

        <h3>3.2 观察历史长度对Token的影响</h3>

        <table class="data-table">
            <thead>
                <tr>
                    <th>history_length</th>
                    <th>第10步单步Token</th>
                    <th>第50步单步Token</th>
                    <th>第100步单步Token</th>
                    <th>100步累积Token</th>
                    <th>节省比例</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>1000 (GM默认)</td>
                    <td>88K</td>
                    <td>130K</td>
                    <td>165K</td>
                    <td>14.2M</td>
                    <td>-</td>
                </tr>
                <tr>
                    <td>500</td>
                    <td>86K</td>
                    <td>120K</td>
                    <td>140K</td>
                    <td>12.8M</td>
                    <td>-10%</td>
                </tr>
                <tr>
                    <td>100 (Agent默认)</td>
                    <td>85K</td>
                    <td>115K</td>
                    <td>120K</td>
                    <td>11.85M</td>
                    <td>-16.5%</td>
                </tr>
                <tr>
                    <td>50</td>
                    <td>83K</td>
                    <td>110K</td>
                    <td>113K</td>
                    <td>11.2M</td>
                    <td>-21%</td>
                </tr>
                <tr>
                    <td>20</td>
                    <td>80K</td>
                    <td>105K</td>
                    <td>107K</td>
                    <td>10.5M</td>
                    <td>-26%</td>
                </tr>
            </tbody>
        </table>

        <div class="info-box">
            <h4>💡 优化建议</h4>
            <p>将LastNObservations的history_length从100降到50：</p>
            <ul>
                <li>单步Token节省：~7-13K</li>
                <li>100步累积节省：~650K tokens</li>
                <li>成本节省：约$6.5 (按GPT-4定价)</li>
                <li><strong>代价：</strong>Agent可访问的历史观察减少一半</li>
            </ul>
        </div>

        <h3>3.3 ThoughtChains复杂度对Token的影响</h3>

        <table class="data-table">
            <thead>
                <tr>
                    <th>ThoughtChain配置</th>
                    <th>EventResolution单次Token</th>
                    <th>单步游戏循环Token</th>
                    <th>100步累积Token</th>
                    <th>时间成本</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>最小（2步）</td>
                    <td>18K</td>
                    <td>95K</td>
                    <td>9.5M</td>
                    <td>~15秒/步</td>
                </tr>
                <tr>
                    <td>标准（3步，默认）</td>
                    <td>29.5K</td>
                    <td>107.6K</td>
                    <td>10.76M</td>
                    <td>~20秒/步</td>
                </tr>
                <tr>
                    <td>扩展（5步）</td>
                    <td>42K</td>
                    <td>120.1K</td>
                    <td>12.01M</td>
                    <td>~28秒/步</td>
                </tr>
                <tr>
                    <td>完整（8步）</td>
                    <td>58K</td>
                    <td>136.1K</td>
                    <td>13.61M</td>
                    <td>~40秒/步</td>
                </tr>
            </tbody>
        </table>

        <div class="warning-box">
            <h4>⚠️ ThoughtChains的双重成本</h4>
            <p>增加ThoughtChain步骤不仅增加Token，还显著增加时间成本：</p>
            <ul>
                <li><strong>Token成本：</strong>每增加1步约+6-8K tokens/游戏步</li>
                <li><strong>时间成本：</strong>每增加1步约+4-6秒/游戏步（串行LLM调用）</li>
                <li><strong>用户体验：</strong>8步ThoughtChains会导致每个游戏步需要40秒，体验很差</li>
            </ul>
            <p><strong>建议：</strong>生产环境使用2-3步ThoughtChains，debug时可增加到5步。</p>
        </div>
    </div>

    <div class="section">
        <h2>4. Token峰值预警与瓶颈识别</h2>

        <h3>4.1 Token峰值预警阈值</h3>

        <table class="data-table">
            <thead>
                <tr>
                    <th>预警级别</th>
                    <th>单步Token阈值</th>
                    <th>累积Token阈值(100步)</th>
                    <th>触发条件</th>
                    <th>建议操作</th>
                </tr>
            </thead>
            <tbody>
                <tr style="background-color: #d4edda;">
                    <td><strong>正常</strong></td>
                    <td>&lt; 100K</td>
                    <td>&lt; 10M</td>
                    <td>2-3玩家，标准配置</td>
                    <td>无需操作</td>
                </tr>
                <tr style="background-color: #fff3cd;">
                    <td><strong>注意</strong></td>
                    <td>100K - 150K</td>
                    <td>10M - 15M</td>
                    <td>4-5玩家，或扩展配置</td>
                    <td>监控成本，考虑优化</td>
                </tr>
                <tr style="background-color: #f8d7da;">
                    <td><strong>警告</strong></td>
                    <td>150K - 200K</td>
                    <td>15M - 20M</td>
                    <td>6-8玩家，或复杂ThoughtChains</td>
                    <td>启用优化配置</td>
                </tr>
                <tr style="background-color: #dc3545; color: white;">
                    <td><strong>危险</strong></td>
                    <td>&gt; 200K</td>
                    <td>&gt; 20M</td>
                    <td>9+玩家，或极端配置</td>
                    <td>重新设计架构</td>
                </tr>
            </tbody>
        </table>

        <h3>4.2 Token瓶颈识别决策树</h3>

        <div class="growth-chart">
Token瓶颈诊断流程图：

                        [单步Token > 150K?]
                                │
                ┌───────────────┴───────────────┐
                │                               │
              YES                              NO
                │                               │
                v                               v
    [make_observation > 50K?]           [Token在合理范围]
                │                         检查增长率
        ┌───────┴───────┐
        │               │
       YES              NO
        │               │
        v               v
    玩家数过多      [EventResolution > 40K?]
    减少玩家            │
    或并行优化      ┌───┴───┐
                    │       │
                   YES      NO
                    │       │
                    v       v
            ThoughtChains  [Agent.act > 30K?]
            过于复杂        │
            减少步骤    ┌───┴───┐
                        │       │
                       YES      NO
                        │       │
                        v       v
                Reflection   LastN过大
                组件过多     减少history
                精简组件     或Memory检索量

<strong>快速诊断检查清单：</strong>

□ 检查玩家数：是否 > 6？
  └─ 是 → 考虑减少玩家或使用Parallel Engine分布式处理

□ 检查make_observation Token占比：是否 > 40%？
  └─ 是 → MakeObservation.max_tokens过大或玩家数过多

□ 检查EventResolution Token占比：是否 > 35%？
  └─ 是 → ThoughtChains步骤过多，移除AccountForAgencyOfOthers

□ 检查Agent.act Token占比：是否 > 25%？
  └─ 是 → Reflection组件过多或LastNObservations过长

□ 检查Token增长率：第50步vs第10步增长 > 50%？
  └─ 是 → Memory检索量或观察历史未设上限
        </div>

        <h3>4.3 实际案例分析</h3>

        <div class="danger-box">
            <h4>🔍 案例1：8玩家游戏Token爆炸</h4>
            <p><strong>症状：</strong>单步Token达到180K，100步累积18M</p>
            <p><strong>诊断：</strong></p>
            <ul>
                <li>make_observation: 8 × 9.2K = 73.6K (占40.9%)</li>
                <li>EventResolution (AccountForAgency): 7 × 3K = 21K (占11.7%)</li>
                <li>其他组件: 85.4K (占47.4%)</li>
            </ul>
            <p><strong>优化方案：</strong></p>
            <ol>
                <li>减少MakeObservation.max_tokens: 1200 → 800（节省3.2K/玩家）</li>
                <li>移除AccountForAgencyOfOthers（节省21K）</li>
                <li>降低LastNObservations: 100 → 50（节省~10K）</li>
            </ol>
            <p><strong>优化后：</strong></p>
            <ul>
                <li>make_observation: 8 × 6K = 48K</li>
                <li>EventResolution: ~15K</li>
                <li>其他: ~75K</li>
                <li><strong>总计: ~138K（节省42K，-23.3%）</strong></li>
            </ul>
        </div>

        <div class="info-box">
            <h4>💡 案例2：长时间游戏（500步）成本优化</h4>
            <p><strong>场景：</strong>4玩家，500步游戏</p>
            <p><strong>原始配置Token消耗：</strong></p>
            <ul>
                <li>累积Token: 61.25M</li>
                <li>估算成本 (GPT-4 $10/1M): $612.5</li>
            </ul>
            <p><strong>优化策略：</strong></p>
            <ol>
                <li>LastNObservations: 100 → 30</li>
                <li>num_memories_to_retrieve: 25 → 15</li>
                <li>简化ThoughtChains: 3步 → 2步</li>
                <li>使用NextActingInFixedOrder（节省10K/步）</li>
            </ol>
            <p><strong>优化后Token消耗：</strong></p>
            <ul>
                <li>单步节省: ~25K</li>
                <li>500步累积: 48.75M（节省12.5M，-20.4%）</li>
                <li><strong>估算成本: $487.5（节省$125，-20.4%）</strong></li>
            </ul>
        </div>
    </div>

    <div class="section">
        <h2>5. 不同游戏模式的Token消耗模式</h2>

        <h3>5.1 Turn-Based vs Real-Time模式</h3>

        <table class="data-table">
            <thead>
                <tr>
                    <th>游戏模式</th>
                    <th>Engine类型</th>
                    <th>单步Token</th>
                    <th>单步时间</th>
                    <th>并发LLM调用</th>
                    <th>适用场景</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>Turn-Based (顺序)</strong></td>
                    <td>Sequential</td>
                    <td>107K</td>
                    <td>20-30秒</td>
                    <td>低（主要串行）</td>
                    <td>桌游、策略游戏</td>
                </tr>
                <tr>
                    <td><strong>Simultaneous (同时行动)</strong></td>
                    <td>Simultaneous</td>
                    <td>140K</td>
                    <td>25-35秒</td>
                    <td>高（所有Agent并行）</td>
                    <td>实时策略、竞技游戏</td>
                </tr>
                <tr>
                    <td><strong>Async (异步)</strong></td>
                    <td>Parallel</td>
                    <td>200K+</td>
                    <td>15-20秒</td>
                    <td>极高（所有阶段并行）</td>
                    <td>大规模模拟</td>
                </tr>
            </tbody>
        </table>

        <h3>5.2 对话式vs任务式游戏</h3>

        <div class="growth-chart">
对话式游戏（如社交模拟）vs 任务式游戏（如冒险游戏）Token对比：

                对话式游戏              任务式游戏
观察长度        较短（30-50 tokens）    较长（50-100 tokens）
Memory类型      主要是对话              主要是事件
Reflection      频繁（每次对话）        较少（关键时刻）
ThoughtChains   简单（2-3步）           复杂（4-6步）

<strong>典型Token消耗（单步，4玩家）：</strong>

对话式：
├─ 观察短，Reflection多
├─ EventResolution简单
└─ 总计: ~85K - 95K

任务式：
├─ 观察长，Reflection少
├─ EventResolution复杂
└─ 总计: ~110K - 130K

<strong>建议配置：</strong>

对话式优化：
├─ 增加LastNObservations（捕捉对话历史）
├─ 减少ThoughtChains复杂度
└─ 使用Conversational prefab

任务式优化：
├─ 减少LastNObservations（任务不依赖全部历史）
├─ 增加ThoughtChains复杂度（精确事件解析）
└─ 使用Basic或BasicWithPlan prefab
        </div>
    </div>

    <div class="section">
        <h2>6. Token监控与实时优化策略</h2>

        <h3>6.1 实时Token监控指标</h3>

        <div class="info-box">
            <h4>📊 建议监控的关键指标</h4>
            <ol>
                <li><strong>单步Token峰值：</strong>每个游戏步的总Token消耗</li>
                <li><strong>累积Token总量：</strong>从游戏开始到当前的累积消耗</li>
                <li><strong>每阶段Token占比：</strong>make_obs / next_acting / agent.act / resolve的占比</li>
                <li><strong>Memory Bank大小：</strong>当前Memory总条数</li>
                <li><strong>平均观察长度：</strong>单条观察的平均token数</li>
                <li><strong>LLM调用次数：</strong>每步调用LLM的总次数</li>
                <li><strong>Token增长率：</strong>相邻步骤间的Token增长百分比</li>
            </ol>
        </div>

        <h3>6.2 自适应Token优化伪代码</h3>

        <div class="formula">
<strong>动态Token优化算法：</strong>

```python
class AdaptiveTokenOptimizer:
    def __init__(self):
        self.token_history = []
        self.step_count = 0
        self.optimization_level = 0  # 0=无, 1=轻度, 2=中度, 3=重度

    def on_step_complete(self, step_tokens):
        self.token_history.append(step_tokens)
        self.step_count += 1

        # 检测Token峰值
        if step_tokens > 150_000:
            self.optimization_level = max(2, self.optimization_level)
        elif step_tokens > 120_000:
            self.optimization_level = max(1, self.optimization_level)

        # 检测增长率
        if self.step_count > 10:
            recent_avg = sum(self.token_history[-10:]) / 10
            early_avg = sum(self.token_history[:10]) / 10
            growth_rate = (recent_avg - early_avg) / early_avg

            if growth_rate > 0.3:  # 增长超过30%
                self.optimization_level = max(1, self.optimization_level)

        # 应用优化
        self.apply_optimization()

    def apply_optimization(self):
        if self.optimization_level == 0:
            return  # 无需优化

        elif self.optimization_level == 1:
            # 轻度优化
            set_history_length(80)  # 从100降到80
            set_num_memories(20)    # 从25降到20

        elif self.optimization_level == 2:
            # 中度优化
            set_history_length(50)
            set_num_memories(15)
            simplify_thought_chains(2)  # 减少到2步

        elif self.optimization_level == 3:
            # 重度优化
            set_history_length(30)
            set_num_memories(10)
            simplify_thought_chains(2)
            use_fixed_acting_order()  # 改用固定顺序
            disable_agency_check()    # 禁用AccountForAgency
```

<strong>触发优化的阈值：</strong>
├─ 单步Token > 150K → 立即启用中度优化
├─ 增长率 > 30% → 启用轻度优化
├─ 累积Token > 预算80% → 启用重度优化
└─ Memory Bank > 500条 → 考虑清理旧记忆
        </div>

        <h3>6.3 预算控制策略</h3>

        <div class="warning-box">
            <h4>💰 Token预算管理</h4>

            <p><strong>设定Token预算（示例：$100预算，GPT-4定价）</strong></p>

            <div class="formula">
总预算: $100
可用Token: 100 / $10/1M = 10M tokens

假设目标: 100步游戏
├─ 平均单步预算: 10M / 100 = 100K tokens/步
├─ 峰值预留(20%): 100K × 0.8 = 80K tokens/步 (安全阈值)
└─ 如果单步超过80K → 触发优化

实时监控：
├─ 当前已用Token: 已用 / 总预算 = 使用率%
├─ 预计剩余步数: (总预算 - 已用) / 平均单步
├─ 预警触发: 使用率 > (步数进度 + 20%)
│   └─ 例: 50%步数完成，但使用率70% → 预警
└─ 强制优化: 使用率 > 90% → 启用重度优化
            </div>

            <p><strong>预算耗尽时的降级策略：</strong></p>
            <ol>
                <li><strong>Phase 1 (预算80%)：</strong>禁用非必要Reflection组件</li>
                <li><strong>Phase 2 (预算90%)：</strong>简化ThoughtChains到最小配置</li>
                <li><strong>Phase 3 (预算95%)：</strong>改用固定Acting Order，禁用所有动态决策</li>
                <li><strong>Phase 4 (预算100%)：</strong>切换到"观察模式"，只记录不生成</li>
            </ol>
        </div>
    </div>

    <div class="section">
        <h2>7. 长期运行的Token治理</h2>

        <h3>7.1 Memory清理策略</h3>

        <div class="info-box">
            <h4>💡 Memory遗忘机制设计</h4>

            <p>虽然Concordia默认不支持Memory删除，但可以实现基于重要性的遗忘：</p>

            <div class="formula">
<strong>重要性衰减模型：</strong>

Importance(t) = I₀ × decay^(current_time - creation_time)

其中：
├─ I₀: 初始重要性（通常=1.0）
├─ decay: 衰减率（例如0.95，每步衰减5%）
├─ current_time: 当前步数
└─ creation_time: Memory创建时的步数

<strong>清理策略：</strong>
1. 定期（每50步）计算所有Memory的importance
2. 保留importance > threshold的Memory（如0.1）
3. 删除importance < threshold的Memory

<strong>特殊保护：</strong>
- 永久保留初始背景故事（设为不可遗忘）
- 保护最近N步的Memory（如最近20步）
- 保护被频繁检索的Memory（访问计数 > 5）

<strong>示例：</strong>
假设decay=0.95，threshold=0.1
├─ 50步前的Memory: 0.95^50 = 0.077 < 0.1 → 删除
├─ 45步前的Memory: 0.95^45 = 0.099 < 0.1 → 删除
├─ 44步前的Memory: 0.95^44 = 0.104 > 0.1 → 保留
└─ 结论: 保留约44步内的Memory
            </div>
        </div>

        <h3>7.2 分层Memory架构</h3>

        <div class="growth-chart">
分层Memory系统（减少长期Token消耗）：

┌──────────────────────────────────────────────────────┐
│  Layer 1: Working Memory (最近20步)                  │
│  ├─ 存储: 所有详细观察和推理                          │
│  ├─ 检索速度: 最快                                    │
│  └─ Token成本: 最高（详细内容）                       │
├──────────────────────────────────────────────────────┤
│  Layer 2: Short-term Memory (21-100步)              │
│  ├─ 存储: 重要事件和关键推理                          │
│  ├─ 检索速度: 快                                      │
│  └─ Token成本: 中（过滤后的内容）                     │
├──────────────────────────────────────────────────────┤
│  Layer 3: Long-term Memory (101-500步)              │
│  ├─ 存储: 总结性事件和重要转折点                      │
│  ├─ 检索速度: 中                                      │
│  └─ Token成本: 低（高度总结）                         │
├──────────────────────────────────────────────────────┤
│  Layer 4: Archive (500+步)                          │
│  ├─ 存储: 仅关键里程碑                                │
│  ├─ 检索速度: 慢（很少访问）                          │
│  └─ Token成本: 极低（仅元数据）                       │
└──────────────────────────────────────────────────────┘

<strong>检索策略：</strong>
retrieve_recent(k):
├─ 优先从Layer 1检索（k1 = min(k, 20)）
├─ 不足则从Layer 2检索（k2 = min(k-k1, 80)）
└─ 仍不足则从Layer 3检索

<strong>Token节省：</strong>
├─ Layer 1: 100 tokens/条 × 20条 = 2,000
├─ Layer 2: 50 tokens/条 × 80条 = 4,000
├─ Layer 3: 20 tokens/条 × 400条 = 8,000
└─ 总计: 14,000 tokens（vs原始50,000 tokens，节省72%）
        </div>

        <h3>7.3 1000+步长期游戏优化方案</h3>

        <table class="data-table">
            <thead>
                <tr>
                    <th>优化措施</th>
                    <th>实施时机</th>
                    <th>Token节省</th>
                    <th>实施难度</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>启用Memory遗忘机制</td>
                    <td>第50步开始，每50步清理一次</td>
                    <td>~15-20%</td>
                    <td>中</td>
                </tr>
                <tr>
                    <td>实施分层Memory</td>
                    <td>从第0步开始</td>
                    <td>~30-40%</td>
                    <td>高</td>
                </tr>
                <tr>
                    <td>动态调整history_length</td>
                    <td>实时，基于Memory增长</td>
                    <td>~10-15%</td>
                    <td>低</td>
                </tr>
                <tr>
                    <td>定期Memory压缩（总结）</td>
                    <td>每100步压缩一次</td>
                    <td>~20-25%</td>
                    <td>中</td>
                </tr>
                <tr>
                    <td>切换到轻量ThoughtChains</td>
                    <td>第200步后</td>
                    <td>~15-20%</td>
                    <td>低</td>
                </tr>
                <tr>
                    <td>禁用低价值Reflection</td>
                    <td>第500步后</td>
                    <td>~10-15%</td>
                    <td>低</td>
                </tr>
            </tbody>
        </table>

        <div class="danger-box">
            <h4>🚨 1000步游戏Token消耗预测</h4>

            <p><strong>无优化场景（4玩家）：</strong></p>
            <ul>
                <li>累积Token: ~125M</li>
                <li>估算成本 (GPT-4): <span class="number-large">$1,250</span></li>
                <li>游戏时长: ~6-8小时（按30秒/步）</li>
            </ul>

            <p><strong>完全优化场景：</strong></p>
            <ul>
                <li>应用所有优化措施</li>
                <li>累积Token: ~60M（节省52%）</li>
                <li>估算成本: <span class="number-large">$600</span>（节省$650）</li>
            </ul>

            <p><strong>建议：</strong>超过500步的游戏应实施至少3项以上优化措施。</p>
        </div>
    </div>

    <div class="section">
        <h2>8. 总结与最佳实践</h2>

        <h3>8.1 Token增长三阶段模型</h3>

        <div class="growth-chart">
Token消耗生命周期：

阶段1: 启动期 (0-30步)
│   特征: 快速增长，Memory和观察历史从空增长
│   增长率: 每步+1,000-1,500 tokens
│   优化重点: 控制初始Memory投喂量
│
阶段2: 加速期 (31-100步)
│   特征: 继续增长，逐步达到检索上限
│   增长率: 每步+500-1,000 tokens
│   优化重点: 确保history_length和num_memories设定合理上限
│
阶段3: 平稳期 (101+步)
│   特征: 增长趋缓，主要来自观察内容变化
│   增长率: 每步+100-300 tokens
│   优化重点: 定期清理Memory，压缩历史

<strong>关键拐点：</strong>
├─ 第25步: retrieve_recent(25)达到上限
├─ 第100步: LastNObservations(100)达到上限
└─ 第200步: 开始考虑Memory清理
        </div>

        <h3>8.2 不同项目类型的Token策略</h3>

        <table class="data-table">
            <thead>
                <tr>
                    <th>项目类型</th>
                    <th>典型规模</th>
                    <th>推荐配置</th>
                    <th>预期Token消耗</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>原型/Demo</strong></td>
                    <td>2-3玩家，10-20步</td>
                    <td>标准配置，无需优化</td>
                    <td>1-2M</td>
                </tr>
                <tr>
                    <td><strong>短游戏体验</strong></td>
                    <td>4玩家，50-100步</td>
                    <td>轻度优化（history=50）</td>
                    <td>5-10M</td>
                </tr>
                <tr>
                    <td><strong>完整游戏Session</strong></td>
                    <td>4-6玩家，200-300步</td>
                    <td>中度优化（Memory清理）</td>
                    <td>20-30M</td>
                </tr>
                <tr>
                    <td><strong>长期模拟</strong></td>
                    <td>6-8玩家，500-1000步</td>
                    <td>重度优化（分层Memory）</td>
                    <td>50-80M</td>
                </tr>
                <tr>
                    <td><strong>大规模研究</strong></td>
                    <td>10+玩家，1000+步</td>
                    <td>定制架构（分布式处理）</td>
                    <td>100M+</td>
                </tr>
            </tbody>
        </table>

        <h3>8.3 Token优化速查表</h3>

        <div class="info-box">
            <h4>✅ Token优化行动清单</h4>

            <p><strong>立即可做（无需改代码）：</strong></p>
            <ul>
                <li>□ 减少玩家数（每减1玩家节省~13.7K/步）</li>
                <li>□ 降低history_length: 100→50（节省~2.5K/步）</li>
                <li>□ 减少num_memories_to_retrieve: 25→15（节省~1K/步）</li>
                <li>□ 使用NextActingInFixedOrder（节省~10K/步）</li>
                <li>□ 简化ThoughtChains步骤（每减1步节省~3.5K/步）</li>
            </ul>

            <p><strong>需要代码调整：</strong></p>
            <ul>
                <li>□ 使用WithoutPreAct组件变体（节省~5-10K/步）</li>
                <li>□ 移除低价值Reflection组件（每个节省~4K/步）</li>
                <li>□ 实施动态Token监控和自适应优化</li>
                <li>□ 定期Memory清理机制（节省15-20%）</li>
            </ul>

            <p><strong>架构级改造：</strong></p>
            <ul>
                <li>□ 分层Memory系统（节省30-40%）</li>
                <li>□ Memory压缩和总结（节省20-25%）</li>
                <li>□ 使用Parallel Engine分布式处理</li>
                <li>□ 实施Token预算管理系统</li>
            </ul>
        </div>
    </div>

    <div class="warning-box" style="margin-top: 40px; background-color: #e8f5e9; border-color: #4caf50;">
        <h3>✅ 文档完成</h3>
        <p><strong>本文档提供了Concordia Token动态增长的深入分析：</strong></p>
        <ul>
            <li>✓ Memory Bank增长模型和Token影响分析</li>
            <li>✓ 100步、500步、1000步游戏的Token累积轨迹</li>
            <li>✓ 不同玩家数和配置下的Token增长对比</li>
            <li>✓ Token峰值预警和瓶颈诊断流程</li>
            <li>✓ 实时Token监控和自适应优化策略</li>
            <li>✓ 长期游戏的Token治理方案</li>
            <li>✓ 完整的Token优化最佳实践</li>
        </ul>
        <p><strong>配合阅读：</strong>concordia_token_analysis_zh.html（静态Token配置分析）</p>
    </div>

</body>
</html>